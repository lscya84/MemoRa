import streamlit as st
import os
import requests
import json
from faster_whisper import WhisperModel
from datetime import datetime

# ëª¨ë¸ ë¡œë“œ (ìºì‹±í•˜ì—¬ ì†ë„ í–¥ìƒ)
# ì£¼ì˜: Streamlitì˜ ìºì‹±ì€ í•´ì‹œ ê°€ëŠ¥í•œ ì¸ìì—¬ì•¼ í•˜ë¯€ë¡œ ëª¨ë¸ ì‚¬ì´ì¦ˆë¥¼ ì¸ìë¡œ ë°›ìŒ
@st.cache_resource
def load_whisper_model(model_size):
    # N100 CPU í™˜ê²½ ìµœì í™” (int8)
    return WhisperModel(model_size, device="cpu", compute_type="int8")

def meeting_page():
    st.header("ğŸ™ï¸ íšŒì˜ ë…¹ìŒ ë¶„ì„")
    st.caption("ë…¹ìŒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ìš”ì•½í•´ì¤ë‹ˆë‹¤.")

    # 1. íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ë…¹ìŒ íŒŒì¼ ì„ íƒ (mp3, wav, m4a)", type=["mp3", "wav", "m4a"])

    if uploaded_file is not None:
        # data í´ë” í™•ì¸ ë° ìƒì„±
        os.makedirs("data", exist_ok=True)
        save_path = os.path.join("data", uploaded_file.name)
        
        with open(save_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        st.info(f"íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ: {uploaded_file.name}")

        # 2. ë¶„ì„ ì‹œì‘ ë²„íŠ¼
        if st.button("ğŸš€ ë¶„ì„ ì‹œì‘ (Transcribe & Summarize)", type="primary"):
            current_model_size = st.session_state.whisper_model_size
            model = load_whisper_model(current_model_size)
            
            # --- STT ë‹¨ê³„ ---
            st.markdown("### 1. í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘...")
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # faster-whisper ì‹¤í–‰
                segments, info = model.transcribe(save_path, beam_size=5)
                
                full_text = ""
                segment_list = [] # íƒ€ì„ìŠ¤íƒ¬í”„ ë“± ì €ì¥ìš©
                
                # ì œë„ˆë ˆì´í„°ì´ë¯€ë¡œ ë£¨í”„ë¥¼ ëŒë©° ì²˜ë¦¬
                for i, segment in enumerate(segments):
                    full_text += segment.text + " "
                    segment_list.append(segment)
                    status_text.text(f"ì²˜ë¦¬ ì¤‘: {segment.start:.1f}s ~ {segment.end:.1f}s")
                    # ì§„í–‰ë¥  ì‹œê°í™” (ì„ì˜ ê³„ì‚°)
                    if i < 90: progress_bar.progress(i + 1)
                
                progress_bar.progress(100)
                status_text.text("í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ!")
                
                with st.expander("ì›ë¬¸ ë³´ê¸° (Transcript)", expanded=False):
                    st.text_area("ì „ì²´ ëŒ€í™” ë‚´ìš©", full_text, height=150)

                # --- ìš”ì•½ ë‹¨ê³„ ---
                st.markdown("### 2. AI ìš”ì•½ ë° ë¶„ì„")
                summary_placeholder = st.empty()
                summary_result = ""

                prompt = f"""
                ë‹¤ìŒ íšŒì˜ ë…¹ì·¨ë¡ì„ ì „ë¬¸ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë³´ê³ ì„œ í˜•íƒœë¡œ ìš”ì•½í•´ì¤˜.
                
                [ìš”ì²­ ì‚¬í•­]
                1. ì „ì²´ ë‚´ìš©ì„ 3ì¤„ë¡œ í•µì‹¬ ìš”ì•½í•  ê²ƒ.
                2. ì£¼ìš” ë…¼ì˜ ì‚¬í•­ì„ ë¶ˆë › í¬ì¸íŠ¸ë¡œ ì •ë¦¬í•  ê²ƒ.
                3. ê²°ì •ëœ ì‚¬í•­(Decisions)ê³¼ í–¥í›„ í•  ì¼(Action Items)ì„ ëª…í™•íˆ ë¶„ë¦¬í•  ê²ƒ.

                [ë…¹ì·¨ë¡]
                {full_text}
                """

                # Ollama í˜¸ì¶œ
                OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")
                llm_model = st.session_state.ollama_model
                
                payload = {
                    "model": llm_model,
                    "prompt": prompt,
                    "stream": True
                }
                
                try:
                    with requests.post(f"{OLLAMA_URL}/api/generate", json=payload, stream=True) as response:
                        for line in response.iter_lines():
                            if line:
                                data = json.loads(line.decode("utf-8"))
                                if "response" in data:
                                    summary_result += data["response"]
                                    summary_placeholder.markdown(summary_result + "â–Œ")
                    
                    summary_placeholder.markdown(summary_result)

                    # --- ê²°ê³¼ ì €ì¥ (History ì—°ë™) ---
                    record = {
                        "date": datetime.now().strftime("%Y-%m-%d %H:%M"),
                        "filename": uploaded_file.name,
                        "full_text": full_text,
                        "summary": summary_result,
                        "model": f"{llm_model} + Whisper-{current_model_size}"
                    }
                    st.session_state.meeting_history.append(record)
                    st.success("âœ… ë¶„ì„ ê²°ê³¼ê°€ íšŒì˜ë¡ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                except Exception as e:
                    st.error(f"Ollama ì—°ê²° ì˜¤ë¥˜: {e}")

            except Exception as e:
                st.error(f"Whisper ë³€í™˜ ì˜¤ë¥˜: {e}")