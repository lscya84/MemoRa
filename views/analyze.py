import streamlit as st
import os
from faster_whisper import WhisperModel
from services import optimize_audio, refine_text_with_ai, transcribe_audio
from database import SessionLocal, Recording, Transcript, init_db

# DB ì´ˆê¸°í™”ëŠ” main.pyì—ì„œ ìˆ˜í–‰í•˜ë¯€ë¡œ ì—¬ê¸°ì„  ìƒëµ ê°€ëŠ¥í•˜ì§€ë§Œ ì•ˆì „ì„ ìœ„í•´ ìœ ì§€
init_db()

@st.cache_resource
def load_model(size, device, compute):
    return WhisperModel(size, device=device, compute_type=compute)

def analyze_page():
    st.header("ğŸ™ï¸ ìŒì„± ë¶„ì„ ë° AI ê²€í† ")
    st.caption("ìŒì„± ì—…ë¡œë“œ -> ì €ìš©ëŸ‰ ìµœì í™” -> AI í…ìŠ¤íŠ¸ ë³€í™˜ -> AI ê²€í† /ìš”ì•½")

    # --- ì‚¬ì´ë“œë°”: Refiner ì„¤ì • ---
    with st.sidebar:
        st.markdown("### ğŸ¤– Refiner ì„¤ì •")
        refiner_api_key = st.text_input("OpenAI/Gemini API Key", type="password")
        refiner_mode = st.selectbox("ê²€í†  ëª¨ë“œ", ["ì˜¤íƒˆì/ë¹„ë¬¸ êµì •", "ìš”ì•½ ìš”ì²­", "ì¤‘ìš” ì‚¬í•­ ì¶”ì¶œ"])

    # 1. íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ìŒì„± íŒŒì¼ ì—…ë¡œë“œ (ìë™ ìµœì í™”)", type=["mp3", "wav", "m4a"])

    if uploaded_file:
        os.makedirs("data/temp", exist_ok=True)
        temp_path = os.path.join("data/temp", uploaded_file.name)
        
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary"):
            status = st.status("ì‘ì—… ì§„í–‰ ì¤‘...", expanded=True)
            
            # [Step 1] Optimize
            status.write("ğŸ’¾ ì˜¤ë””ì˜¤ ìµœì í™” ì§„í–‰ ì¤‘...")
            optimized_path = optimize_audio(temp_path, output_folder="data/storage")
            
            if not optimized_path:
                status.error("ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨ (FFmpeg ì„¤ì¹˜ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”)")
                status.update(label="ì‘ì—… ì‹¤íŒ¨", state="error")
                return

            try:
                # [Step 2] Analyze (STT)
                status.write("ğŸ“ Whisper AIê°€ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")
                
                w_size = st.session_state.get("whisper_model", "base")
                w_device = st.session_state.get("whisper_device", "cpu")
                w_compute = st.session_state.get("whisper_compute", "int8")
                
                model = load_model(w_size, w_device, w_compute)
                full_text, segments_list = transcribe_audio(model, optimized_path)
                
                status.write("âœ… ë¶„ì„ ì™„ë£Œ!")
                
                st.session_state.current_script = full_text
                st.session_state.current_segments = segments_list
                st.session_state.optimized_path = optimized_path

                # [Step 3] DB Archive
                status.write("ğŸ—‚ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
                db = SessionLocal()
                
                new_rec = Recording(
                    filename=os.path.basename(optimized_path),
                    file_path=optimized_path,
                    file_size=os.path.getsize(optimized_path) / (1024*1024),
                    processed=1
                )
                db.add(new_rec)
                db.commit()
                db.refresh(new_rec)
                
                new_trans = Transcript(
                    recording_id=new_rec.id,
                    full_text=full_text,
                    segments_json=segments_list,
                    version=1
                )
                db.add(new_trans)
                db.commit()
                db.close()
                
                status.update(label="ëª¨ë“  ì‘ì—… ì™„ë£Œ!", state="complete", expanded=False)

            except Exception as e:
                status.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                status.update(label="ì‘ì—… ì¤‘ë‹¨", state="error")

    # --- ê²°ê³¼ ê²€í†  ë° AI ìš”ì²­ UI ---
    if "current_script" in st.session_state:
        st.divider()
        st.subheader("ğŸ“ ìŠ¤í¬ë¦½íŠ¸ ê²€í† ")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            script_area = st.text_area("ë³€í™˜ëœ í…ìŠ¤íŠ¸", value=st.session_state.current_script, height=300)
            st.caption("ğŸ‘‡ ì•„ë˜ ë‚´ìš©ì„ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”")
            st.code(script_area, language="text")

        with col2:
            st.info("ğŸ¤– AI Refiner")
            st.write(f"ëª¨ë“œ: **{refiner_mode}**")
            
            if st.button("AIì—ê²Œ ê²€í† /ìˆ˜ì • ìš”ì²­"):
                if not refiner_api_key:
                    st.error("ì‚¬ì´ë“œë°”ì— API Keyë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("AIê°€ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                        mode_map = {
                            "ì˜¤íƒˆì/ë¹„ë¬¸ êµì •": "fix",
                            "ìš”ì•½ ìš”ì²­": "summarize",
                            "ì¤‘ìš” ì‚¬í•­ ì¶”ì¶œ": "action_item"
                        }
                        
                        try:
                            ai_config = {
                                "ollama_url": st.session_state.get("ollama_url"),
                                "ollama_model": st.session_state.get("ollama_model"),
                                "api_key": refiner_api_key
                            }
                            result = refine_text_with_ai(script_area, ai_config, mode_map[refiner_mode])
                            
                            st.success("ê²€í†  ì™„ë£Œ!")
                            st.text_area("AI ë¶„ì„ ê²°ê³¼", value=result, height=200)
                            st.caption("ê²°ê³¼ ë³µì‚¬:")
                            st.code(result, language="text")
                        except Exception as e:
                            st.error(f"AI ìš”ì²­ ì‹¤íŒ¨: {e}")
